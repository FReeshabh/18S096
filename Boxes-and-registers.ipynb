{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1: Boxes and Registers\n",
    "\n",
    "This is an [IJulia notebook](https://github.com/JuliaLang/IJulia.jl) (the [Jupyter](http://jupyter.org/)-based front-end for Julia) for [18.S096 at MIT in IAP 2017](https://math.mit.edu/classes/18.S096/iap17/), designed to accompany the first lecture.\n",
    "\n",
    "The basic goal of this lecture is to understand why some code (in some languages and/or styles of coding) is slow while other code is fast, based on whether it can be compiled to efficiently use the CPU registers and low-level arithmetic instructions, or whether it relies on \"boxed\" types that force \"dynamic\" computations.\n",
    "\n",
    "To illustrate this, we will implement a **sum** function `sum(a)`, which computes\n",
    "$$\n",
    "\\operatorname{sum}(a) = \\sum_{i=1}^n a_i\n",
    "$$\n",
    "for an array `a` with `n` elements.   We will use both the built-in `sum` functions in Julia and Python along with hand-coded implementations in C, Python, and Julia.\n",
    "\n",
    "We will use some tricks so that we can write and benchmark C, Python, and Julia code all in the same notebook.  In the case of Python, this will rely on the [PyCall](https://github.com/JuliaPy/PyCall.jl) package to call Python from Julia.  We will use the [BenchmarkTools](https://github.com/JuliaCI/BenchmarkTools.jl) Julia package to collect benchmarking statistics for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level C code\n",
    "\n",
    "To start with, we will write a baseline implementation in the low-level C programming language.  Our C function `c_sum` will only work for a single data type: an array `X` of double-precision floating-point values (`double` in C, or `Float64` in Julia).\n",
    "\n",
    "(In contrast, our Julia code, and some of our Python code, will work for any numeric type; we'll see whether we pay a price for this.)\n",
    "\n",
    "Julia can easily call C functions in shared libraries via its `ccall` syntax.  So, we'll take our C routine (in a string), write it to a file, and pass it through the C compiler `gcc` to produce a shared library that we can load and call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_sum (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_code = \"\"\"\n",
    "#include <stddef.h>\n",
    "double c_sum(size_t n, double *X) {\n",
    "    double s = 0.0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        s += X[i];\n",
    "    }\n",
    "    return s;\n",
    "}\n",
    "\"\"\"\n",
    "# compile to a shared library by piping C_code to gcc:\n",
    "# (only works if you have gcc installed)\n",
    "const Clib = tempname()\n",
    "open(`gcc -fPIC -O3 -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code)\n",
    "end\n",
    "c_sum(X::Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we should first check whether our function is correct, by comparing it to Julia's built-in `sum` function on an array of $10^7$ random numbers.  Different floating-point algorithms for the `sum` function give slightly different results (Julia's `sum` algorithm is actually *much more accurate* than the one here, but that's a story for another day), so we'll compute their \"fractional difference\" or \"relative error\" and make sure that this is small.  \n",
    "\n",
    "(Double-precision floating-point arithmetic keeps about 15 decimal digits, so any relative error close to $10^{-15}$ is a reasonable amount of roundoff error.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6767184263763773e-14"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to compute the relative (fractional) error |x-y| / mean(|x|,|y|)\n",
    "relerr(x,y) = abs(x - y) * 2 / (abs(x) + abs(y))\n",
    "\n",
    "a = rand(10^7) # array of random numbers in [0,1)\n",
    "relerr(c_sum(a), sum(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting accurate benchmarking statistics can be a tricky business, so we'll use the Julia `BenchmarkTools` package to do most of the work.   If you don't have it installed, you may need to type `Pkg.add(\"BenchmarkTools\")` to tell Julia to download and install it.\n",
    "\n",
    "It defines a *macro* `@benchmark` that takes some Julia code and *transforms* it into a benchmark measuring the speed of that code.   We pass the argument `a` of the `c_sum` function to be benchmarked by the special syntax `$a` for technical reasons, basically to make sure that Julia's analysis of the variable `a` happens *before* the benchmark starts.  Macro syntax and **metaprogramming** will be a topic for another lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          572\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  0.00 bytes\n",
       "  allocs estimate:  0\n",
       "  minimum time:     8.14 ms (0.00% GC)\n",
       "  median time:      8.43 ms (0.00% GC)\n",
       "  mean time:        8.74 ms (0.00% GC)\n",
       "  maximum time:     12.45 ms (0.00% GC)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "c_bench = @benchmark c_sum($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, the most useful number to look at in a benchmark is the **minimum time**.  Basically, your computer is doing lots of things all of the time, and creates random interruptions that can cause spikes in the timing that we want to ignore.\n",
    "\n",
    "Here, the minimum time is around **8 ms** for summing $10^7$ numbers, or about **1 billion additions per second**.  That sounds like a lot, but on my **2.5GHz laptop** it is well below the peak rate at which the computer can perform arithmetic.   It doesn't reach the peak arithmetic rate because for each floating-point addition, the processor needs to perform several additional calculations to load the next element of the array from memory, not to mention the time for the memory access itself.  Of course, you may get a slightly different number if you run this benchmark on a different computer.\n",
    "\n",
    "This **8 ms** number for type-specific compiled C code is a baseline against which we will compare our other implementations of summation, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python sum functions\n",
    "\n",
    "Now, we'll call the Python functions and benchmark them.   The PyCall package allows to load Python as a library and to call it directly from Julia, sharing memory with Python and passing data and functions back and forth.  There is very little overhead to this, and in any case we will be summing $10^7$ numbers so the overhead of the Julia/Python interface is negligible compared to the cost of the summation itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"2.7.12\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "PyCall.pyversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### built-in `sum` of a Python `list`\n",
    "\n",
    "To start with, I will convert our array `a` into a Python `list` (the built-in Python array-like data structure), and sum it with the built-in Python `sum` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <built-in function sum>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call a low-level PyCall function to get a Python list, because\n",
    "# by default PyCall will convert to a NumPy array instead (we benchmark NumPy below):\n",
    "apy_list = PyCall.array2py(a, 1, 1)\n",
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we can call it, and that it computes the same answer as the Julia `sum`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6767184263763773e-14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relerr(pysum(apy_list), sum(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll benchmark it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          60\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  672.00 bytes\n",
       "  allocs estimate:  19\n",
       "  minimum time:     72.39 ms (0.00% GC)\n",
       "  median time:      83.81 ms (0.00% GC)\n",
       "  mean time:        83.65 ms (0.00% GC)\n",
       "  maximum time:     95.42 ms (0.00% GC)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_list_bench = @benchmark $pysum($apy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes **72 ms**, or almost **10x slower** than the C routine above.  This is true **even though the Python sum** function is [written in almost 200 lines of C code](https://github.com/python/cpython/blob/b5be30c92ff8cc0ac83f48014fe78bc048141021/Python/bltinmodule.c#L2191-L2365).   The problem is that the Python code *pays a price for being generic*: it handles arbitrary iterable data structures of arbitrary numeric \"boxes\" (`PyObject` pointers), and has to perform lots of computations both to fetch each item and also to perform each addition.\n",
    "\n",
    "### NumPy `sum` of a NumPy `array`\n",
    "\n",
    "You can do *much better* if you can take advantage of the fact that *all of the elements are the same type*.  Then, you can store the array as the actual floating-point data stored consecutively in memory (not an array of pointers to boxes), and your inner loop can be fast because the type checks can occur *outside* the loop. In Python, this kind of **homogeneous array** is exactly what is provided by [NumPy](http://www.numpy.org/). Internally, a NumPy array is essentially just a wrapper around a C-like `double*` array.   NumPy\n",
    "also provides `numpy.sum` function that can sum a NumPy array quickly.\n",
    "\n",
    "There is a catch, though: NumPy itself is written mostly in C, not Python.  And because C code is not type-generic, in order to handle a wide variety of NumPy array types (integers, double precision, single precision, etcetera), NumPy uses rather tricky **auto-generated C code**.  And even then it can only handle a small set of commonly used types; you can't define your own types and sum them quickly.\n",
    "\n",
    "Anyway, we can easily convert a Julia array to a NumPy array with PyCall (in fact, PyCall does this by\n",
    "by default), and benchmark `numpy.sum`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          1063\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  960.00 bytes\n",
       "  allocs estimate:  25\n",
       "  minimum time:     3.94 ms (0.00% GC)\n",
       "  median time:      4.42 ms (0.00% GC)\n",
       "  mean time:        4.70 ms (0.00% GC)\n",
       "  maximum time:     8.80 ms (0.00% GC)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum = pyimport(\"numpy\")[\"sum\"]\n",
    "apy_numpy = PyObject(a) # converts to a numpy array by default\n",
    "py_numpy_bench = @benchmark $numpy_sum($apy_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOW, it is actually **roughly twice as fast** as our C function!\n",
    "\n",
    "The reason for this extra boost is that the NumPy functions exploit [SIMD instructions](https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions): special CPU instructions that can perform multiple additions at once, which we didn't use in our C code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand-written Python `sum` function\n",
    "\n",
    "To complete the story, let's write our own `mysum` function in Python that sums an arbitrary Python list (or array, or any iterable Python container).\n",
    "\n",
    "Of course, you would never do this for summation — you would always use one of the built-in\n",
    "functions in practice.  But someday, you will inevitably run into a problem where the\n",
    "performance-critical code has not already been written for you, and you will need to write\n",
    "your own.  So it is a good exercise to see how easy it is to get performance that\n",
    "is comparable to the library routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function mysum at 0x3342e27d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It currently takes a little bit of hackery to define a custom Python function\n",
    "# in a Julia string and call it via PyCall, sorry:\n",
    "syms = PyDict{AbstractString, PyObject}()\n",
    "syms[\"syms\"] = PyObject(Any[])\n",
    "pyeval(\"\"\"\n",
    "def mysum(a):\n",
    "    s = 0.0\n",
    "    for x in a:\n",
    "        s = s + x\n",
    "    return s\n",
    "\n",
    "syms.insert(0, mysum)\n",
    "\"\"\", PyAny, syms, PyCall.Py_file_input)\n",
    "mysum_py = syms[\"syms\"][1] # a reference to the Python mysum function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's check that it works, first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6767184263763773e-14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relerr(mysum_py(apy_list), sum(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's time it on our Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          4\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  672.00 bytes\n",
       "  allocs estimate:  19\n",
       "  minimum time:     1.38 s (0.00% GC)\n",
       "  median time:      1.41 s (0.00% GC)\n",
       "  mean time:        1.42 s (0.00% GC)\n",
       "  maximum time:     1.48 s (0.00% GC)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark $mysum_py($apy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes, **1.4 seconds**.  That's **20× slower than the Python `sum`** and almost **200× slower than our C code**.\n",
    "\n",
    "Using our `mysum` function with the NumPy array is no better, and in fact is a bit worse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          3\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  960.00 bytes\n",
       "  allocs estimate:  25\n",
       "  minimum time:     1.86 s (0.00% GC)\n",
       "  median time:      1.89 s (0.00% GC)\n",
       "  mean time:        1.89 s (0.00% GC)\n",
       "  maximum time:     1.92 s (0.00% GC)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark $mysum_py($apy_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't take advantage of the NumPy array format in Python itself — you still have to write the performance-critical code in C (or hope someone else has written it for you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in Julia `sum` function\n",
    "\n",
    "Now, let's try the same thing in Julia, starting with the built-in Julia `sum` function operating on our array `a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          1208\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  0.00 bytes\n",
       "  allocs estimate:  0\n",
       "  minimum time:     3.75 ms (0.00% GC)\n",
       "  median time:      4.07 ms (0.00% GC)\n",
       "  mean time:        4.14 ms (0.00% GC)\n",
       "  maximum time:     6.41 ms (0.00% GC)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench = @benchmark sum($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray **3.75 ms**.  That's more than **2× the speed of the C code**, and slightly faster than even `numpy.sum`.  Again, you can guess that it must be using SIMD to beat the C code.  And, again, it must be taking advantage of the fact that the array is homogeneous.\n",
    "\n",
    "The type of `a` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Float64,1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Julia type for a 1-dimensional array of `Float64` values (64-bit \"double\" precision floating-point numbers, equivalent to C `double`).  Because the type of the elements is \"attached\" to the type of the array (a \"parameterized\" type, more on this later), Julia is able to store it as a \"flat\" array of consecutive `Float64` values in memory.\n",
    "\n",
    "In contrast, the Julia equivalent of a Python `list` is a `Vector{Any}` (a synonym for `Array{Any,1}`): internally, this is an array of pointers to \"boxes\" that can hold any type (`Any`).  This makes things *much* slower: each `+` computation on an `Any` value must dynamically look up the type of object, figure out what `+` function to call, and allocate a new \"box\" to store the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          26\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  153.09 mb\n",
       "  allocs estimate:  10032767\n",
       "  minimum time:     186.89 ms (2.09% GC)\n",
       "  median time:      195.00 ms (2.08% GC)\n",
       "  mean time:        198.25 ms (2.06% GC)\n",
       "  maximum time:     216.78 ms (1.73% GC)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_any = Vector{Any}(a)\n",
    "j_bench_any = @benchmark sum($a_any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is **187 ms**, or a **50× slowdown**.  It is more than **2× slower than the Python `sum(list)` code**, in fact.  The Python `sum` function is better optimized than the Julia `sum` function for dealing with untyped (`Any`) values, because in Julia it is expected that you will used \"concretely\" typed arrays in all performance-critical cases.\n",
    "\n",
    "Unlike NumPy, however, Julia allows you to make efficient homogeneous arrays for any data type, even data types you define yourself, and you can operate on them efficiently with code written in Julia itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand-written Julia `sum` functions\n",
    "\n",
    "Let's try to write our own `sum` function in Julia, just as we wrote our own Python function.  We'll implement four different versions and see how they compare.  We'll start simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6767184263763773e-14"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum1(A)\n",
    "    s = 0\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "relerr(mysum1(a), sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          23\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  457.76 mb\n",
       "  allocs estimate:  30000000\n",
       "  minimum time:     205.36 ms (3.83% GC)\n",
       "  median time:      223.93 ms (3.86% GC)\n",
       "  mean time:        225.01 ms (3.90% GC)\n",
       "  maximum time:     243.05 ms (3.65% GC)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j1_bench = @benchmark mysum1($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes!  The performance is **terrible**, more than **200ms**.\n",
    "\n",
    "However, it turns out we made a simple mistake: we had a **type instability** in our code, because the summation variable `s` **changes type** in our function.  It starts out as an *integer* `0` (a Julia `Int`), but once we do `s += a` (shorthand for `s = s + a`), the result *changes* to a floating-point value.  Julia's compiler is quite simple-minded about such things: **once it sees that a variable changes type, it assumes it can be any type** and stores it in a \"box\".\n",
    "\n",
    "One symptom of this is the \"allocs estimate: 30000000\" line above: it is doing *zillions of allocations* in order to allocate all the \"boxes\" for the untyped `s` values.  Another way of seeing this would be to use the `@code_warntype` macro provided with Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables:\n",
      "  #self#::#mysum1\n",
      "  A::Array{Float64,1}\n",
      "  s\u001b[1m\u001b[31m::Any\u001b[0m\n",
      "  #temp#@_4::Int64\n",
      "  a::Float64\n",
      "  #temp#@_6::LambdaInfo\n",
      "  #temp#@_7::Float64\n",
      "\n",
      "Body:\n",
      "  begin \n",
      "      s\u001b[1m\u001b[31m::Any\u001b[0m = 0 # line 3:\n",
      "      #temp#@_4::Int64 = $(QuoteNode(1))\n",
      "      4: \n",
      "      unless (Base.box)(Base.Bool,(Base.not_int)((#temp#@_4::Int64 === (Base.box)(Int64,(Base.add_int)((Base.arraylen)(A::Array{Float64,1})::Int64,1)))::Bool)) goto 29\n",
      "      SSAValue(2) = (Base.arrayref)(A::Array{Float64,1},#temp#@_4::Int64)::Float64\n",
      "      SSAValue(3) = (Base.box)(Int64,(Base.add_int)(#temp#@_4::Int64,1))\n",
      "      a::Float64 = SSAValue(2)\n",
      "      #temp#@_4::Int64 = SSAValue(3) # line 4:\n",
      "      unless (Core.isa)(s\u001b[1m\u001b[31m::Union{Float64,Int64}\u001b[0m,Float64)\u001b[1m\u001b[31m::Any\u001b[0m goto 14\n",
      "      #temp#@_6::LambdaInfo = LambdaInfo for +(::Float64, ::Float64)\n",
      "      goto 23\n",
      "      14: \n",
      "      unless (Core.isa)(s\u001b[1m\u001b[31m::Union{Float64,Int64}\u001b[0m,Int64)\u001b[1m\u001b[31m::Any\u001b[0m goto 18\n",
      "      #temp#@_6::LambdaInfo = LambdaInfo for +(::Int64, ::Float64)\n",
      "      goto 23\n",
      "      18: \n",
      "      goto 20\n",
      "      20: \n",
      "      #temp#@_7::Float64 = (s\u001b[1m\u001b[31m::Union{Float64,Int64}\u001b[0m + a::Float64)::Float64\n",
      "      goto 25\n",
      "      23: \n",
      "      #temp#@_7::Float64 = $(Expr(:invoke, :(#temp#@_6), :(Main.+), :(s::Union{Float64,Int64}), :(a)))\n",
      "      25: \n",
      "      s\u001b[1m\u001b[31m::Any\u001b[0m = #temp#@_7::Float64\n",
      "      27: \n",
      "      goto 4\n",
      "      29:  # line 6:\n",
      "      return s\u001b[1m\u001b[31m::Union{Float64,Int64}\u001b[0m\n",
      "  end\u001b[1m\u001b[31m::Union{Float64,Int64}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "@code_warntype mysum1(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tip-off here is the `s::Any` lines, telling you that `s` is stored in a \"box\" that holds type `Any`.  In computer-science lingo, we would say that **compiler type inference has failed** to determine the type of `s`.   More on this below.\n",
    "\n",
    "One solution would be to initialize `s = 0.0`, i.e. start `s` out as a floating-point value.  This would work for our floating-point array `a`, but then wouldn't work for other types of arrays.  Instead, Julia provides an `eltype(A)` function to fetch the *type of the elements* of `A`, and a `zero` function to *initialize `s` to the correct type of zero* for `A`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6767184263763773e-14"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum2(A)\n",
    "    s = zero(eltype(A))\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "relerr(mysum2(a), sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          562\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  0.00 bytes\n",
       "  allocs estimate:  0\n",
       "  minimum time:     8.14 ms (0.00% GC)\n",
       "  median time:      8.79 ms (0.00% GC)\n",
       "  mean time:        8.91 ms (0.00% GC)\n",
       "  maximum time:     12.83 ms (0.00% GC)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j2_bench = @benchmark mysum2($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's more like it!  It runs in **8.14 ms**, essentially the **same speed as the hand-written C code**.\n",
    "\n",
    "*Unlike* the C code, however, it works for *any* type of array, and in fact just about any type of \"iterable container\" (as long as it provides an `eltype` method), and can **sum any type of value** (as long as `zero` and `+` are defined), including user-defined types.  (We'll give an example below).\n",
    "\n",
    "The performance does not quite match the Julia built-in `sum` function or the `numpy.sum` function, however.  Our guess above was that they were exploiting SIMD optimizations.  However, we can do that too, in our own Julia code, by using the `@simd` decorator to tell Julia's compiler to turn on SIMD optimizations for that loop.\n",
    "\n",
    "(SIMD optimizations are not turned on by default, because they only speed up very particular kinds of code, and turning them on everywhere would slow down the compiler too much.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition mysum3(Any) in module Main at In[21]:2 overwritten at In[23]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.285631758645321e-14"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum3(A)\n",
    "    s = zero(eltype(A))\n",
    "    @simd for a in A\n",
    "        s += a\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "relerr(mysum3(a), sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          1237\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  0.00 bytes\n",
       "  allocs estimate:  0\n",
       "  minimum time:     3.68 ms (0.00% GC)\n",
       "  median time:      4.04 ms (0.00% GC)\n",
       "  mean time:        4.04 ms (0.00% GC)\n",
       "  maximum time:     6.23 ms (0.00% GC)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j3_bench = @benchmark mysum3($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hooray!  **3.68 ms**, basically the same speed as Julia's built-in `sum` function and `numpy.sum`!   And it only required **7 lines of code**, some care with types, and a very minor bit of wizardry with the `@simd` tag to get the last factor of two.\n",
    "\n",
    "Moreover, the code is still **type generic**: it can sum any container of any type that works with addition.   And we **didn't have to declare any types** of any arguments or variables; the compiler figured everything out.  How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type inference and specialization\n",
    "\n",
    "To go any further, you need to understand something very basic about how Julia works.  Suppose we define a very simple function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't declare the type of `x`, and so our function `f(x)` will work with **any type of `x`** (as long as the `+ 1` operation is defined for that type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3) # x is an integer (technically, a 64-bit integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3.1) # x is a floating-point value (Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f([1,2,3]) # x is an array of integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can a function like `f(x)` work for any type?  In Python, `x` would be a \"box\" that could contain anything, and it would then look up *at runtime* how to compute `x + 1`.  But we just saw that untyped Julia `sum` code could be fast.\n",
    "\n",
    "The secret is **just-in-time (JIT) compilation**.   The first time you call `f(x)` **with a new type of argument** `x`, it will **compile a new version of `f` specialized for that type**.  The *next* time it calls `f(x)` with the same argument type\n",
    "\n",
    "So, right now, after evaluating the above code, we have *three* versions of `f` compiled and sitting in memory: one for `x` of type `Int` (we say `x::Int` in Julia), one for `x::Float64`, and one for `x::Vector{Int}`.\n",
    "\n",
    "We can even see what the compiled code for `f(x::Int)` looks like, either the [compiler (LLVM) bytecode](https://en.wikipedia.org/wiki/LLVM) or the low-level (below C!) [assembly code](https://en.wikipedia.org/wiki/Assembly_language):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "define i64 @julia_f_72252(i64) #0 {\n",
      "top:\n",
      "  %1 = add i64 %0, 1\n",
      "  ret i64 %1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "@code_llvm f(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.section\t__TEXT,__text,regular,pure_instructions\n",
      "Filename: In[25]\n",
      "\tpushq\t%rbp\n",
      "\tmovq\t%rsp, %rbp\n",
      "Source line: 1\n",
      "\tleaq\t1(%rdi), %rax\n",
      "\tpopq\t%rbp\n",
      "\tretq\n",
      "\tnopw\t(%rax,%rax)\n"
     ]
    }
   ],
   "source": [
    "@code_native f(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break this down.  When you tell Julia's compiler that `x` is an `Int`, it:\n",
    "\n",
    "* It knows `x` fits into a 64-bit CPU register (and is passed to the function via a register).\n",
    "\n",
    "* Looks at `x + 1`.  Since `x` and `1` are both `Int`, it knows it should call the `+` function for two `Int` values.  This corresponds to *one machine instruction* `leaq` to add two 64-bit registers.\n",
    "\n",
    "* Since the `+` function here is so simple, it won't bother to do a function call.  It will [inline](https://en.wikipedia.org/wiki/Inline_expansion) the `(+)(Int,Int)` function into the compiled `f(x)` code.\n",
    "\n",
    "* Since it now knows what `+` function it is calling, it knows that the *result* of the `+` is *also* an `Int`, and it can return it via register.\n",
    "\n",
    "This process works recursively if we define a new function `g(x)` that calls `f(x)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(x) = f(x) + 3\n",
    "g(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "define i64 @julia_g_72356(i64) #0 {\n",
      "top:\n",
      "  %1 = add i64 %0, 4\n",
      "  ret i64 %1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "@code_llvm g(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it specialized `g` for `x::Int`, it not only figured out what `f` function to call, it not only *inlined* `f(x)` *into `g`*, but the compiler was smart enough to *combine the two additions* into a single addition `x + 4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defeating type inference: Type instabilities\n",
    "\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our own types\n",
    "\n",
    "Let's define our own type to represent a **\"point\" in two dimensions**.  Each point will have an $(x,y)$ location.  So that we can use the points with our `sum` functions above, we'll also define `+` and `zero` functions to do the obvious **vector addition**.\n",
    "\n",
    "The simplest such definition in Julia is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition (::Type{Main.Point1})(Any, Any) in module Main at In[33]:2 overwritten at In[34]:2.\n",
      "WARNING: Method definition +(Main.Point1, Main.Point1) in module Main at In[33]:5 overwritten at In[34]:5.\n",
      "WARNING: Method definition zero(Type{Main.Point1}) in module Main at In[33]:6 overwritten at In[34]:6.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Point1(3,4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Point1\n",
    "    x\n",
    "    y\n",
    "end\n",
    "Base.:+(p::Point1, q::Point1) = Point1(p.x + q.x, p.y + q.y)\n",
    "Base.zero(::Type{Point1}) = Point1(0,0)\n",
    "\n",
    "Point1(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point1(8,10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Point1(3,4) + Point1(5,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our type is very generic, and can hold any type of `x` and `y` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point1(3.7,4 + 5im)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Point1(3.7, 4+5im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps too generic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point1(\"x\",[3,4,5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Point1(\"x\", [3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `x` and `y` can be *anything*, they must be **pointers to \"boxes\"**.  This is **bad news for performance**.\n",
    "\n",
    "A `type` is *mutable*, which means we can create a `Point1` object and then change `x` or `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point1(7,4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Point1(3,4)\n",
    "p.x = 7\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that every reference to a `Point1` object must be a *pointer* to an object stored elsewhere in memory, because *how else would we \"know\" when an object changes?*  Furthermore, an **array of `Point1` objects must be an array of pointers** (which is **bad news for performance** again):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Point1,1}:\n",
       " Point1(7,4)\n",
       " Point1(7,4)\n",
       " Point1(7,4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = [p,p,p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Point1,1}:\n",
       " Point1(7,8)\n",
       " Point1(7,8)\n",
       " Point1(7,8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.y = 8\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can avoid these two problems by:\n",
    "\n",
    "* Declare the types of `x` and `y` to be *concrete* types, so that they don't need to be pointers to boxes.\n",
    "* Declare our Point to be an `immutable` type (`x` and `y` cannot change), so that Julia is not forced to make every reference to a Point into a pointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point2(3.0,4.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immutable Point2\n",
    "    x::Float64\n",
    "    y::Float64\n",
    "end\n",
    "Base.:+(p::Point2, q::Point2) = Point2(p.x + q.x, p.y + q.y)\n",
    "Base.zero(::Type{Point2}) = Point1(0.0,0.0)\n",
    "\n",
    "Point2(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point2(8.0,10.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Point2(3,4) + Point2(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Point2,1}:\n",
       " Point2(3.0,4.0)\n",
       " Point2(3.0,4.0)\n",
       " Point2(3.0,4.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Point2(3,4)\n",
    "P = [p,p,p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "type Point2 is immutable",
     "output_type": "error",
     "traceback": [
      "type Point2 is immutable",
      ""
     ]
    }
   ],
   "source": [
    "p.x = 6 # gives an error since p is immutable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best of both worlds: Parameterized immutable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point3{Int64}(3,4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Point3{T<:Real}\n",
    "    x::T\n",
    "    y::T\n",
    "end\n",
    "Base.:+(p::Point3, q::Point3) = Point3(p.x + q.x, p.y + q.y)\n",
    "Base.zero{T}(::Type{Point3{T}}) = Point1(zero(T),zero(T))\n",
    "\n",
    "Point3(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point3{Float64}(8.6,11.8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Point3(3,4) + Point3(5.6, 7.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
