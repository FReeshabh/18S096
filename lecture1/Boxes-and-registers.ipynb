{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1: Boxes and Registers\n",
    "\n",
    "This is an [IJulia notebook](https://github.com/JuliaLang/IJulia.jl) (the [Jupyter](http://jupyter.org/)-based front-end for Julia) for [18.S096 at MIT in IAP 2017](https://math.mit.edu/classes/18.S096/iap17/), designed to accompany the first lecture.\n",
    "\n",
    "The basic goal of this lecture is to understand why some code (in some languages and/or styles of coding) is slow while other code is fast, based on whether it can be compiled to efficiently use the CPU registers and low-level arithmetic instructions, or whether it relies on \"boxed\" types that force \"dynamic\" computations.\n",
    "\n",
    "To illustrate this, we will implement a **sum** function `sum(a)`, which computes\n",
    "\n",
    "$$\n",
    "\\mathrm{sum}(a) = \\sum_{i=1}^n a_i\n",
    "$$\n",
    "\n",
    "for an array `a` with `n` elements.   We will use the built-in `sum` functions in Julia and Python along with hand-coded implementations in C, Python, and Julia.\n",
    "\n",
    "We will use some tricks so that we can write and benchmark C, Python, and Julia code all in the same notebook.  In the case of Python, this will rely on the [PyCall](https://github.com/JuliaPy/PyCall.jl) package to call Python from Julia.  We will use the [BenchmarkTools](https://github.com/JuliaCI/BenchmarkTools.jl) Julia package to collect benchmarking statistics for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level C code\n",
    "\n",
    "To start with, we will write a baseline implementation in the low-level C programming language.  Our C function `c_sum` will only work for a single data type: an array `X` of double-precision floating-point values (`double` in C, or `Float64` in Julia).\n",
    "\n",
    "(In contrast, our Julia code, and some of our Python code, will work for any numeric type; we'll see whether we pay a price for this.)\n",
    "\n",
    "Julia can easily call C functions in shared libraries via its `ccall` syntax.  So, we'll take our C routine (in a string) and pipe it through the C compiler `gcc` to produce a shared library file that we can load and call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_sum (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_code = \"\"\"\n",
    "#include <stddef.h>\n",
    "double c_sum(size_t n, double *X) {\n",
    "    double s = 0.0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        s += X[i];\n",
    "    }\n",
    "    return s;\n",
    "}\n",
    "\"\"\"\n",
    "# compile to a shared library by piping C_code to gcc:\n",
    "# (only works if you have gcc installed)\n",
    "const Clib = tempname()\n",
    "open(`gcc -fPIC -O3 -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code)\n",
    "end\n",
    "c_sum(X::Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we should first check whether our function is correct, by comparing it to Julia's built-in `sum` function on an array of $10^7$ random numbers.  Different floating-point algorithms for the `sum` function give slightly different results (Julia's `sum` algorithm is actually *much more accurate* than the one here, but that's a story for another day), so we'll compute their \"fractional difference\" or \"relative error\" and make sure that this is small.  \n",
    "\n",
    "(Double-precision floating-point arithmetic keeps about 15 decimal digits, so any relative error close to $10^{-15}$ is a reasonable amount of roundoff error.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7358575333763837e-13"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to compute the relative (fractional) error |x-y| / mean(|x|,|y|)\n",
    "relerr(x,y) = abs(x - y) * 2 / (abs(x) + abs(y))\n",
    "\n",
    "a = rand(10^7) # array of random numbers in [0,1)\n",
    "relerr(c_sum(a), sum(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting accurate benchmarking statistics can be a tricky business, so we'll use the Julia `BenchmarkTools` package to do most of the work.   If you don't have it installed, you may need to type `Pkg.add(\"BenchmarkTools\")` to tell Julia to download and install it.\n",
    "\n",
    "It defines a *macro* `@benchmark` that takes some Julia code and *transforms* it into a benchmark measuring the speed of that code.   We pass the argument `a` of the `c_sum` function to be benchmarked by the special syntax `$a` for technical reasons, basically to make sure that Julia's analysis of the variable `a` happens *before* the benchmark starts.  Macro syntax and **metaprogramming** will be a topic for another lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          520\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  0.00 bytes\n",
       "  allocs estimate:  0\n",
       "  minimum time:     8.14 ms (0.00% GC)\n",
       "  median time:      9.10 ms (0.00% GC)\n",
       "  mean time:        9.61 ms (0.00% GC)\n",
       "  maximum time:     14.58 ms (0.00% GC)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "c_bench = @benchmark c_sum($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, the most useful number to look at in a benchmark is the **minimum time**.  Basically, your computer is doing lots of things all of the time, and creates random interruptions that can cause spikes in the timing that we want to ignore.\n",
    "\n",
    "Here, the minimum time is around **8 ms** for summing $10^7$ numbers, or about **1 billion additions per second**.  That sounds like a lot, but on my **2.5GHz laptop** it is well below the peak rate at which the computer can perform arithmetic.   It doesn't reach the peak arithmetic rate because for each floating-point addition, the processor needs to perform several additional calculations to load the next element of the array from memory, not to mention the time for the memory access itself.  Of course, you may get a slightly different number if you run this benchmark on a different computer.\n",
    "\n",
    "This **8 ms** number for type-specific compiled C code is a baseline against which we will compare our other implementations of summation, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python sum functions\n",
    "\n",
    "Now, we'll call the Python functions and benchmark them.   The PyCall package allows to load Python as a library and to call it directly from Julia, sharing memory with Python and passing data and functions back and forth.  There is very little overhead to this, and in any case we will be summing $10^7$ numbers so the overhead of the Julia/Python interface is negligible compared to the cost of the summation itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"2.7.12\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "PyCall.pyversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### built-in `sum` of a Python `list`\n",
    "\n",
    "To start with, I will convert our array `a` into a Python `list` (the built-in Python array-like data structure), and sum it with the built-in Python `sum` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <built-in function sum>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call a low-level PyCall function to get a Python list, because\n",
    "# by default PyCall will convert to a NumPy array instead (we benchmark NumPy below):\n",
    "apy_list = PyCall.array2py(a, 1, 1)\n",
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we can call it, and that it computes the same answer as the Julia `sum`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7358575333763837e-13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relerr(pysum(apy_list), sum(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll benchmark it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          56\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  672.00 bytes\n",
       "  allocs estimate:  19\n",
       "  minimum time:     73.23 ms (0.00% GC)\n",
       "  median time:      91.34 ms (0.00% GC)\n",
       "  mean time:        90.37 ms (0.00% GC)\n",
       "  maximum time:     104.63 ms (0.00% GC)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_list_bench = @benchmark $pysum($apy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes **70 ms**, or almost **10x slower** than the C routine above.  This is true **even though the Python sum** function is [written in almost 200 lines of C code](https://github.com/python/cpython/blob/b5be30c92ff8cc0ac83f48014fe78bc048141021/Python/bltinmodule.c#L2191-L2365).   The problem is that the Python code *pays a price for being generic*: it handles arbitrary iterable data structures of arbitrary numeric \"boxes\" (`PyObject` pointers), and has to perform lots of computations both to fetch each item and also to perform each addition.\n",
    "\n",
    "### NumPy `sum` of a NumPy `array`\n",
    "\n",
    "You can do *much better* if you can take advantage of the fact that *all of the elements are the same type*.  Then, you can store the array as the actual floating-point data stored consecutively in memory (not an array of pointers to boxes), and your inner loop can be fast because the type checks can occur *outside* the loop. In Python, this kind of **homogeneous array** is exactly what is provided by [NumPy](http://www.numpy.org/). Internally, a NumPy array is essentially just a wrapper around a C-like `double*` array.   NumPy\n",
    "also provides `numpy.sum` function that can sum a NumPy array quickly.\n",
    "\n",
    "There is a catch, though: NumPy itself is written mostly in C, not Python.  And because C code is not type-generic, in order to handle a wide variety of NumPy array types (integers, double precision, single precision, etcetera), NumPy uses rather tricky **auto-generated C code**.  And even then it can only handle a small set of commonly used types; you can't define your own types and sum them quickly.\n",
    "\n",
    "Anyway, we can easily convert a Julia array to a NumPy array with PyCall (in fact, PyCall does this by\n",
    "by default), and benchmark `numpy.sum`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          1150\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  960.00 bytes\n",
       "  allocs estimate:  25\n",
       "  minimum time:     3.94 ms (0.00% GC)\n",
       "  median time:      4.29 ms (0.00% GC)\n",
       "  mean time:        4.35 ms (0.00% GC)\n",
       "  maximum time:     7.80 ms (0.00% GC)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum = pyimport(\"numpy\")[\"sum\"]\n",
    "apy_numpy = PyObject(a) # converts to a numpy array by default\n",
    "py_numpy_bench = @benchmark $numpy_sum($apy_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOW, it is actually **roughly twice as fast** as our C function!\n",
    "\n",
    "The reason for this extra boost is that the NumPy functions exploit [SIMD instructions](https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions): special CPU instructions that can perform multiple additions at once, which we didn't use in our C code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand-written Python `sum` function\n",
    "\n",
    "To complete the story, let's write our own `mysum` function in Python that sums an arbitrary Python list (or array, or any iterable Python container).\n",
    "\n",
    "Of course, you would never do this for summation — you would always use one of the built-in\n",
    "functions in practice.  But someday, you will inevitably run into a problem where the\n",
    "performance-critical code has not already been written for you, and you will need to write\n",
    "your own.  So it is a good exercise to see how easy it is to get performance that\n",
    "is comparable to the library routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function mysum at 0x336a197d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It currently takes a little bit of hackery to define a custom Python function\n",
    "# in a Julia string and call it via PyCall, sorry:\n",
    "syms = PyDict{AbstractString, PyObject}()\n",
    "syms[\"syms\"] = PyObject(Any[])\n",
    "pyeval(\"\"\"\n",
    "def mysum(a):\n",
    "    s = 0.0\n",
    "    for x in a:\n",
    "        s = s + x\n",
    "    return s\n",
    "\n",
    "syms.insert(0, mysum)\n",
    "\"\"\", PyAny, syms, PyCall.Py_file_input)\n",
    "mysum_py = syms[\"syms\"][1] # a reference to the Python mysum function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's check that it works, first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7358575333763837e-13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relerr(mysum_py(apy_list), sum(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's time it on our Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          4\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  672.00 bytes\n",
       "  allocs estimate:  19\n",
       "  minimum time:     1.30 s (0.00% GC)\n",
       "  median time:      1.32 s (0.00% GC)\n",
       "  mean time:        1.33 s (0.00% GC)\n",
       "  maximum time:     1.36 s (0.00% GC)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark $mysum_py($apy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes, **1.3 seconds**.  That's **20× slower than the Python `sum`** and almost **200× slower than our C code**.\n",
    "\n",
    "Using our `mysum` function with the NumPy array is no better, and in fact is a bit worse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          3\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  960.00 bytes\n",
       "  allocs estimate:  25\n",
       "  minimum time:     1.82 s (0.00% GC)\n",
       "  median time:      1.83 s (0.00% GC)\n",
       "  mean time:        1.85 s (0.00% GC)\n",
       "  maximum time:     1.88 s (0.00% GC)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark $mysum_py($apy_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't take advantage of the NumPy array format in Python itself — you still have to write the performance-critical code in C (or hope someone else has written it for you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in Julia `sum` function\n",
    "\n",
    "Now, let's try the same thing in Julia, starting with the built-in Julia `sum` function operating on our array `a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          1150\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  0.00 bytes\n",
       "  allocs estimate:  0\n",
       "  minimum time:     3.74 ms (0.00% GC)\n",
       "  median time:      4.10 ms (0.00% GC)\n",
       "  mean time:        4.35 ms (0.00% GC)\n",
       "  maximum time:     10.03 ms (0.00% GC)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench = @benchmark sum($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray **3.7 ms**.  That's more than **2× the speed of the C code**, and slightly faster than even `numpy.sum`.  Again, you can guess that it must be using SIMD to beat the C code.  And, again, it must be taking advantage of the fact that the array is homogeneous.\n",
    "\n",
    "The type of `a` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Float64,1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Julia type for a 1-dimensional array of `Float64` values (64-bit \"double\" precision floating-point numbers, equivalent to C `double`).  Because the type of the elements is \"attached\" to the type of the array (a \"parameterized\" type, more on this later), Julia is able to store it as a \"flat\" array of consecutive `Float64` values in memory.\n",
    "\n",
    "In contrast, the Julia equivalent of a Python `list` is a `Vector{Any}` (a synonym for `Array{Any,1}`): internally, this is an array of pointers to \"boxes\" that can hold any type (`Any`).  This makes things *much* slower: each `+` computation on an `Any` value must dynamically look up the type of object, figure out what `+` function to call, and allocate a new \"box\" to store the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          24\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  153.09 mb\n",
       "  allocs estimate:  10032767\n",
       "  minimum time:     201.18 ms (1.76% GC)\n",
       "  median time:      209.44 ms (1.83% GC)\n",
       "  mean time:        208.61 ms (1.86% GC)\n",
       "  maximum time:     224.10 ms (1.95% GC)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_any = Vector{Any}(a)\n",
    "j_bench_any = @benchmark sum($a_any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is **187 ms**, or a **50× slowdown**.  It is more than **2× slower than the Python `sum(list)` code**, in fact.  The Python `sum` function is better optimized than the Julia `sum` function for dealing with untyped (`Any`) values, in part because in Julia it is expected that you will use \"concretely\" typed arrays in all performance-critical cases.\n",
    "\n",
    "Unlike NumPy, however, Julia allows you to make efficient homogeneous arrays for any data type, even data types you define yourself, and you can operate on them efficiently with code written in Julia itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand-written Julia `sum` functions\n",
    "\n",
    "Let's try to write our own `sum` function in Julia, just as we wrote our own Python function.  We'll implement four different versions and see how they compare.  We'll start simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7358575333763837e-13"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum1(A)\n",
    "    s = 0\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "relerr(mysum1(a), sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          24\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  457.76 mb\n",
       "  allocs estimate:  30000000\n",
       "  minimum time:     203.60 ms (3.78% GC)\n",
       "  median time:      208.03 ms (3.85% GC)\n",
       "  mean time:        208.85 ms (3.85% GC)\n",
       "  maximum time:     215.05 ms (3.72% GC)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j1_bench = @benchmark mysum1($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes!  The performance is **terrible**, more than **200ms**.\n",
    "\n",
    "However, it turns out we made a simple mistake: we had a **type instability** in our code, because the summation variable `s` **changes type** in our function.  It starts out as an *integer* `0` (a Julia `Int`), but once we do `s += a` (shorthand for `s = s + a`), the result *changes* to a floating-point value.  Julia's compiler is quite simple-minded about such things: **once it sees that a variable changes type, it assumes it can be any type** and stores it in a \"box\".\n",
    "\n",
    "One symptom of this is the \"allocs estimate: 30000000\" line above: it is doing *zillions of allocations* in order to allocate all the \"boxes\" for the untyped `s` values.  Another way of seeing this would be to use the `@code_warntype` macro provided with Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables:\n",
      "  #self#::#mysum1\n",
      "  A::Array{Float64,1}\n",
      "  s\u001b[1m\u001b[31m::Any\u001b[0m\n",
      "  #temp#@_4::Int64\n",
      "  a::Float64\n",
      "  #temp#@_6::LambdaInfo\n",
      "  #temp#@_7::Float64\n",
      "\n",
      "Body:\n",
      "  begin \n",
      "      s\u001b[1m\u001b[31m::Any\u001b[0m = 0 # line 3:\n",
      "      #temp#@_4::Int64 = $(QuoteNode(1))\n",
      "      4: \n",
      "      unless (Base.box)(Base.Bool,(Base.not_int)((#temp#@_4::Int64 === (Base.box)(Int64,(Base.add_int)((Base.arraylen)(A::Array{Float64,1})::Int64,1)))::Bool)) goto 29\n",
      "      SSAValue(2) = (Base.arrayref)(A::Array{Float64,1},#temp#@_4::Int64)::Float64\n",
      "      SSAValue(3) = (Base.box)(Int64,(Base.add_int)(#temp#@_4::Int64,1))\n",
      "      a::Float64 = SSAValue(2)\n",
      "      #temp#@_4::Int64 = SSAValue(3) # line 4:\n",
      "      unless (Core.isa)(s\u001b[1m\u001b[31m::Union{Float64,Int64}\u001b[0m,Float64)\u001b[1m\u001b[31m::Any\u001b[0m goto 14\n",
      "      #temp#@_6::LambdaInfo = LambdaInfo for +(::Float64, ::Float64)\n",
      "      goto 23\n",
      "      14: \n",
      "      unless (Core.isa)(s\u001b[1m\u001b[31m::Union{Float64,Int64}\u001b[0m,Int64)\u001b[1m\u001b[31m::Any\u001b[0m goto 18\n",
      "      #temp#@_6::LambdaInfo = LambdaInfo for +(::Int64, ::Float64)\n",
      "      goto 23\n",
      "      18: \n",
      "      goto 20\n",
      "      20: \n",
      "      #temp#@_7::Float64 = (s\u001b[1m\u001b[31m::Union{Float64,Int64}\u001b[0m + a::Float64)::Float64\n",
      "      goto 25\n",
      "      23: \n",
      "      #temp#@_7::Float64 = $(Expr(:invoke, :(#temp#@_6), :(Main.+), :(s::Union{Float64,Int64}), :(a)))\n",
      "      25: \n",
      "      s\u001b[1m\u001b[31m::Any\u001b[0m = #temp#@_7::Float64\n",
      "      27: \n",
      "      goto 4\n",
      "      29:  # line 6:\n",
      "      return s\u001b[1m\u001b[31m::Union{Float64,Int64}\u001b[0m\n",
      "  end\u001b[1m\u001b[31m::Union{Float64,Int64}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "@code_warntype mysum1(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tip-off here is the `s::Any` lines, telling you that `s` is stored in a \"box\" that holds type `Any`.  In computer-science lingo, we would say that **compiler type inference has failed** to determine the type of `s`.   More on this below.\n",
    "\n",
    "One solution would be to initialize `s = 0.0`, i.e. start `s` out as a floating-point value.  This would work for our floating-point array `a`, but then wouldn't work for other types of arrays.  Instead, Julia provides an `eltype(A)` function to fetch the *type of the elements* of `A`, and a `zero` function to *initialize `s` to the correct type of zero* for `A`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7358575333763837e-13"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum2(A)\n",
    "    s = zero(eltype(A))\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "relerr(mysum2(a), sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          548\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  0.00 bytes\n",
       "  allocs estimate:  0\n",
       "  minimum time:     8.14 ms (0.00% GC)\n",
       "  median time:      8.81 ms (0.00% GC)\n",
       "  mean time:        9.13 ms (0.00% GC)\n",
       "  maximum time:     13.18 ms (0.00% GC)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j2_bench = @benchmark mysum2($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's more like it!  It runs in **8 ms**, essentially the **same speed as the hand-written C code**.\n",
    "\n",
    "*Unlike* the C code, however, it works for *any* type of array, and in fact just about any type of \"iterable container\" (as long as it provides an `eltype` method), and can **sum any type of value** (as long as `zero` and `+` are defined), including user-defined types.  (We'll give an example below).\n",
    "\n",
    "The performance does not quite match the Julia built-in `sum` function or the `numpy.sum` function, however.  Our guess above was that they were exploiting SIMD optimizations.  However, we can do that too, in our own Julia code, by using the `@simd` decorator to tell Julia's compiler to turn on SIMD optimizations for that loop.\n",
    "\n",
    "(SIMD optimizations are not turned on by default, because they only speed up very particular kinds of code, and turning them on everywhere would slow down the compiler too much.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1361299306432493e-14"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum3(A)\n",
    "    s = zero(eltype(A))\n",
    "    @simd for a in A\n",
    "        s += a\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "relerr(mysum3(a), sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          1166\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  0.00 bytes\n",
       "  allocs estimate:  0\n",
       "  minimum time:     3.68 ms (0.00% GC)\n",
       "  median time:      4.11 ms (0.00% GC)\n",
       "  mean time:        4.29 ms (0.00% GC)\n",
       "  maximum time:     7.81 ms (0.00% GC)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j3_bench = @benchmark mysum3($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hooray!  **3.7 ms**, basically the same speed as Julia's built-in `sum` function and `numpy.sum`!   And it only required **7 lines of code**, some care with types, and a very minor bit of wizardry with the `@simd` tag to get the last factor of two.\n",
    "\n",
    "Moreover, the code is still **type generic**: it can sum any container of any type that works with addition.   And we **didn't have to declare any types** of any arguments or variables; the compiler figured everything out.  How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type inference and specialization\n",
    "\n",
    "To go any further, you need to understand something very basic about how Julia works.  Suppose we define a very simple function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't declare the type of `x`, and so our function `f(x)` will work with **any type of `x`** (as long as the `+ 1` operation is defined for that type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3) # x is an integer (technically, a 64-bit integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3.1) # x is a floating-point value (Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f([1,2,3]) # x is an array of integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can a function like `f(x)` work for any type?  In Python, `x` would be a \"box\" that could contain anything, and it would then look up *at runtime* how to compute `x + 1`.  But we just saw that untyped Julia `sum` code could be fast.\n",
    "\n",
    "The secret is **just-in-time (JIT) compilation**.   The first time you call `f(x)` **with a new type of argument** `x`, it will **compile a new version of `f` specialized for that type**.  The *next* time it calls `f(x)` with the same argument type\n",
    "\n",
    "So, right now, after evaluating the above code, we have *three* versions of `f` compiled and sitting in memory: one for `x` of type `Int` (we say `x::Int` in Julia), one for `x::Float64`, and one for `x::Vector{Int}`.\n",
    "\n",
    "We can even see what the compiled code for `f(x::Int)` looks like, either the [compiler (LLVM) bytecode](https://en.wikipedia.org/wiki/LLVM) or the low-level (below C!) [assembly code](https://en.wikipedia.org/wiki/Assembly_language):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "define i64 @julia_f_72157(i64) #0 {\n",
      "top:\n",
      "  %1 = add i64 %0, 1\n",
      "  ret i64 %1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "@code_llvm f(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.section\t__TEXT,__text,regular,pure_instructions\n",
      "Filename: In[23]\n",
      "\tpushq\t%rbp\n",
      "\tmovq\t%rsp, %rbp\n",
      "Source line: 1\n",
      "\tleaq\t1(%rdi), %rax\n",
      "\tpopq\t%rbp\n",
      "\tretq\n",
      "\tnopw\t(%rax,%rax)\n"
     ]
    }
   ],
   "source": [
    "@code_native f(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break this down.  When you tell Julia's compiler that `x` is an `Int`, it:\n",
    "\n",
    "* It knows `x` fits into a 64-bit CPU register (and is passed to the function via a register).\n",
    "\n",
    "* Looks at `x + 1`.  Since `x` and `1` are both `Int`, it knows it should call the `+` function for two `Int` values.  This corresponds to *one machine instruction* `leaq` to add two 64-bit registers.\n",
    "\n",
    "* Since the `+` function here is so simple, it won't bother to do a function call.  It will [inline](https://en.wikipedia.org/wiki/Inline_expansion) the `(+)(Int,Int)` function into the compiled `f(x)` code.\n",
    "\n",
    "* Since it now knows what `+` function it is calling, it knows that the *result* of the `+` is *also* an `Int`, and it can return it via register.\n",
    "\n",
    "This process works recursively if we define a new function `g(x)` that calls `f(x)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(x) = f(x) + 3\n",
    "g(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "define i64 @julia_g_72261(i64) #0 {\n",
      "top:\n",
      "  %1 = add i64 %0, 4\n",
      "  ret i64 %1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "@code_llvm g(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it specialized `g` for `x::Int`, it not only figured out what `f` function to call, it not only *inlined* `f(x)` *into `g`*, but the compiler was smart enough to *combine the two additions* into a single addition `x + 4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defeating type inference: Type instabilities\n",
    "\n",
    "To get good performance, there are some fairly simple rules that you need to follow in Julia code to avoid defeating the compiler's type inference.   See also the [performance tips section of the Julia manual](http://docs.julialang.org/en/stable/manual/performance-tips/).\n",
    "\n",
    "Three of the most important are:\n",
    "\n",
    "* Don't use (non-constant) global variables in critical code — put your critical code into a function (this is good advice anyway, from a software-engineering standpoint).  The compiler assumes that a **global variable can change type at any time**, so it is always stored in a \"box\", and \"taints\" anything that depends on it.\n",
    "\n",
    "* Local variables should be \"type-stable\": **don't change the type of a variable inside a function**.  Use a new variable instead.\n",
    "\n",
    "* Functions should be \"type-stable\": **a function's return type should only depend on the argument types, not on the argument values**.\n",
    "\n",
    "To diagnose all of these problems, the `@code_warntype` macro that we used above is your friend.  If it labels any variables (or the function's return value) as `Any` or `Union{...}`, it means that the compiler couldn't figure out a precise type.\n",
    "\n",
    "The third point, type-stability of functions, leads to lots of important but subtle choices in library design.  For example, consider the (built-in) `sqrt(x)` function, which computes $\\sqrt{x}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might think that `sqrt(-1)` should return $i$ (or `im`, in Julia syntax).  (Matlab's `sqrt` function does this.)  Instead, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DomainError:\nsqrt will only return a complex result if called with a complex argument. Try sqrt(complex(x)).",
     "output_type": "error",
     "traceback": [
      "DomainError:\nsqrt will only return a complex result if called with a complex argument. Try sqrt(complex(x)).",
      "",
      " in sqrt(::Int64) at ./math.jl:211"
     ]
    }
   ],
   "source": [
    "sqrt(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0 + 1.0im"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(-1 + 0im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did Julia implement `sqrt` in this silly way, throwing an error for negative arguments unless you add a zero imaginary part?  Any reasonable person wants an imaginary result from `sqrt(-1)`, surely?\n",
    "\n",
    "The problem is that defining `sqrt` to return an imaginary result from `sqrt(-1)` would **not be type stable**: `sqrt(x)` would return a real result for non-negative real `x`, and a complex result for negative real `x`, so the **return type would depend on the value of `x`** and **not just its type.**\n",
    "\n",
    "That would defeat type inference, not just for the `sqrt` function, but for **anything the sqrt function touches**.  Unless the compiler can somehow figure out `x ≥ 0`, it will have to either store the result in a \"box\" or compile two branches of the result.  Let's see how that works by defining our own square-root function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysqrt (generic function with 2 methods)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysqrt(x::Complex) = sqrt(x)\n",
    "mysqrt(x::Real) = x < 0 ? sqrt(complex(x)) : sqrt(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This definition is an example of Julia's [multiple dispatch style](http://docs.julialang.org/en/stable/manual/methods/), which in some sense is a generalization of object-oriented programming but focuses on \"verbs\" (functions) rather than nouns.  We will discuss this more in a later lecture.\n",
    "\n",
    "The `::Complex` and `::Real` are argument-type declarations.  Such declarations are **not related to performance**, but instead **act as a \"filter\"** to allow us to have one version of `mysqrt` for complex arguments and another for real arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0 + 1.4142135623730951im"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysqrt(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0 + 1.4142135623730951im"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysqrt(-2+0im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great, right?  But let's see what happens to type inference in a function that calls `mysqrt` instead of `sqrt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables:\n",
      "  #self#::#slowfun\n",
      "  x::Int64\n",
      "  #temp#@_3\u001b[1m\u001b[31m::Union{Complex{Float64},Float64}\u001b[0m\n",
      "  #temp#@_4::LambdaInfo\n",
      "  #temp#@_5\u001b[1m\u001b[31m::Union{Complex{Float64},Float64}\u001b[0m\n",
      "\n",
      "Body:\n",
      "  begin \n",
      "      # meta: location In[34] mysqrt 2\n",
      "      unless (Base.slt_int)(x::Int64,0)::Bool goto 5\n",
      "      #temp#@_3\u001b[1m\u001b[31m::Union{Complex{Float64},Float64}\u001b[0m = $(Expr(:invoke, LambdaInfo for sqrt(::Complex{Float64}), :(Base.sqrt), :($(Expr(:new, Complex{Float64}, :((Base.box)(Float64,(Base.sitofp)(Float64,x))), :((Base.box)(Float64,(Base.sitofp)(Float64,0))))))))\n",
      "      goto 7\n",
      "      5: \n",
      "      #temp#@_3\u001b[1m\u001b[31m::Union{Complex{Float64},Float64}\u001b[0m = (Base.Math.box)(Base.Math.Float64,(Base.Math.sqrt_llvm)((Base.box)(Float64,(Base.sitofp)(Float64,x::Int64))))::Float64\n",
      "      7: \n",
      "      # meta: pop location\n",
      "      unless (Core.isa)(#temp#@_3\u001b[1m\u001b[31m::Union{Complex{Float64},Float64}\u001b[0m,Float64)\u001b[1m\u001b[31m::Any\u001b[0m goto 12\n",
      "      #temp#@_4::LambdaInfo = LambdaInfo for +(::Float64, ::Int64)\n",
      "      goto 21\n",
      "      12: \n",
      "      unless (Core.isa)(#temp#@_3\u001b[1m\u001b[31m::Union{Complex{Float64},Float64}\u001b[0m,Complex{Float64})\u001b[1m\u001b[31m::Any\u001b[0m goto 16\n",
      "      #temp#@_4::LambdaInfo = LambdaInfo for +(::Complex{Float64}, ::Int64)\n",
      "      goto 21\n",
      "      16: \n",
      "      goto 18\n",
      "      18: \n",
      "      #temp#@_5\u001b[1m\u001b[31m::Union{Complex{Float64},Float64}\u001b[0m = (#temp#@_3\u001b[1m\u001b[31m::Union{Complex{Float64},Float64}\u001b[0m + 1)\u001b[1m\u001b[31m::Union{Complex{Float64},Float64}\u001b[0m\n",
      "      goto 23\n",
      "      21: \n",
      "      #temp#@_5\u001b[1m\u001b[31m::Union{Complex{Float64},Float64}\u001b[0m = $(Expr(:invoke, :(#temp#@_4), :(Main.+), :(#temp#@_3), 1))\n",
      "      23: \n",
      "      return #temp#@_5\u001b[1m\u001b[31m::Union{Complex{Float64},Float64}\u001b[0m\n",
      "  end\u001b[1m\u001b[31m::Union{Complex{Float64},Float64}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "slowfun(x) = mysqrt(x) + 1\n",
    "@code_warntype slowfun(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the compiler **doesn't know at compile-time that x is positive** (at compile-time it **uses only types, not values**, it doesn't know whether the result is real (`Float64`) or complex (`Complex{Float64}`) and has to store it in a \"box\".  This kills performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our own types\n",
    "\n",
    "Let's define our own type to represent a **\"point\" in two dimensions**.  Each point will have an $(x,y)$ location.  So that we can use the points with our `sum` functions above, we'll also define `+` and `zero` functions to do the obvious **vector addition**.\n",
    "\n",
    "The simplest such definition in Julia is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point1(3,4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Point1\n",
    "    x\n",
    "    y\n",
    "end\n",
    "Base.:+(p::Point1, q::Point1) = Point1(p.x + q.x, p.y + q.y)\n",
    "Base.zero(::Type{Point1}) = Point1(0,0)\n",
    "\n",
    "Point1(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point1(8,10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Point1(3,4) + Point1(5,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our type is very generic, and can hold any type of `x` and `y` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point1(3.7,4 + 5im)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Point1(3.7, 4+5im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps too generic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point1(\"x\",[3,4,5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Point1(\"x\", [3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `x` and `y` can be *anything*, they must be **pointers to \"boxes\"**.  This is **bad news for performance**.\n",
    "\n",
    "A `type` is *mutable*, which means we can create a `Point1` object and then change `x` or `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point1(7,4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Point1(3,4)\n",
    "p.x = 7\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that every reference to a `Point1` object must be a *pointer* to an object stored elsewhere in memory, because *how else would we \"know\" when an object changes?*  Furthermore, an **array of `Point1` objects must be an array of pointers** (which is **bad news for performance** again):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Point1,1}:\n",
       " Point1(7,4)\n",
       " Point1(7,4)\n",
       " Point1(7,4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = [p,p,p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Point1,1}:\n",
       " Point1(7,8)\n",
       " Point1(7,8)\n",
       " Point1(7,8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.y = 8\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this out by creating an array of `Point1` objects and summing it.  Ideally, this would be about twice as slow as summing an equal-length array of numbers, since there are twice as many numbers to sum.  But because of all of the boxes and pointer-chasing, it should be far slower.\n",
    "\n",
    "To create the array, we'll call the `Point1(x,y)` constructor with our array `a`, using Julia's [\"dot-call\" syntax](http://docs.julialang.org/en/stable/manual/functions/#dot-syntax-for-vectorizing-functions) that applies a function \"element-wise\" to arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000-element Array{Point1,1}:\n",
       " Point1(0.0854553,0.0854553)\n",
       " Point1(0.885596,0.885596)  \n",
       " Point1(0.204148,0.204148)  \n",
       " Point1(0.291398,0.291398)  \n",
       " Point1(0.491761,0.491761)  \n",
       " Point1(0.385552,0.385552)  \n",
       " Point1(0.858012,0.858012)  \n",
       " Point1(0.610907,0.610907)  \n",
       " Point1(0.202762,0.202762)  \n",
       " Point1(0.772584,0.772584)  \n",
       " Point1(0.0807838,0.0807838)\n",
       " Point1(0.942604,0.942604)  \n",
       " Point1(0.525602,0.525602)  \n",
       " ⋮                          \n",
       " Point1(0.450704,0.450704)  \n",
       " Point1(0.6765,0.6765)      \n",
       " Point1(0.0218983,0.0218983)\n",
       " Point1(0.60217,0.60217)    \n",
       " Point1(0.601585,0.601585)  \n",
       " Point1(0.906846,0.906846)  \n",
       " Point1(0.0805392,0.0805392)\n",
       " Point1(0.346368,0.346368)  \n",
       " Point1(0.764284,0.764284)  \n",
       " Point1(0.420253,0.420253)  \n",
       " Point1(0.596481,0.596481)  \n",
       " Point1(0.485411,0.485411)  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = Point1.(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          11\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  610.35 mb\n",
       "  allocs estimate:  29999997\n",
       "  minimum time:     445.14 ms (5.68% GC)\n",
       "  median time:      484.73 ms (5.89% GC)\n",
       "  mean time:        479.87 ms (6.14% GC)\n",
       "  maximum time:     505.38 ms (6.74% GC)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark sum($a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          11\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  610.35 mb\n",
       "  allocs estimate:  30000001\n",
       "  minimum time:     471.91 ms (6.24% GC)\n",
       "  median time:      488.49 ms (6.34% GC)\n",
       "  mean time:        486.19 ms (6.39% GC)\n",
       "  maximum time:     502.19 ms (6.23% GC)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark mysum3($a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time is about **450–500ms**, at least 50× slower than we would like, but consistent with our other timing results on \"boxed\" values from above.\n",
    "\n",
    "By the way, we can also use our `relerr` function to compare the two summation algorithms (which work without modification on our new type, hooray!), but we'll need to define `-` and `abs` first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7358575333763837e-13"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base.:-(p::Point1, q::Point1) = Point1(p.x - q.x, p.y - q.y)\n",
    "Base.abs(p::Point1) = hypot(p.x, p.y) # sqrt(p.x^2 + p.y^2)\n",
    "relerr(sum(a1),mysum3(a1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An imperfect solution: A concrete immutable type\n",
    "\n",
    "We can avoid these two problems by:\n",
    "\n",
    "* Declare the types of `x` and `y` to be *concrete* types, so that they don't need to be pointers to boxes.\n",
    "* Declare our Point to be an `immutable` type (`x` and `y` cannot change), so that Julia is not forced to make every reference to a Point into a pointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point2(3.0,4.0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immutable Point2\n",
    "    x::Float64\n",
    "    y::Float64\n",
    "end\n",
    "Base.:+(p::Point2, q::Point2) = Point2(p.x + q.x, p.y + q.y)\n",
    "Base.zero(::Type{Point2}) = Point2(0.0,0.0)\n",
    "\n",
    "Point2(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point2(8.0,10.0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Point2(3,4) + Point2(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Point2,1}:\n",
       " Point2(3.0,4.0)\n",
       " Point2(3.0,4.0)\n",
       " Point2(3.0,4.0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Point2(3,4)\n",
    "P = [p,p,p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "type Point2 is immutable",
     "output_type": "error",
     "traceback": [
      "type Point2 is immutable",
      ""
     ]
    }
   ],
   "source": [
    "p.x = 6 # gives an error since p is immutable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is working as we hope, then summation should be much faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          352\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  0.00 bytes\n",
       "  allocs estimate:  0\n",
       "  minimum time:     10.15 ms (0.00% GC)\n",
       "  median time:      13.24 ms (0.00% GC)\n",
       "  mean time:        14.21 ms (0.00% GC)\n",
       "  maximum time:     23.04 ms (0.00% GC)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = Point2.(a,a)\n",
    "@benchmark sum($a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the time is **only 10ms**, only slightly more than twice the cost of summing an array of individual numbers of the same length!\n",
    "\n",
    "Unfortunately, we paid a big price for this performance: our `Point2` type only works with *a single numeric type* (`Float64`), much like a C implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best of both worlds: Parameterized immutable types\n",
    "\n",
    "How do we get a `Point` type that works for *any* type of `x` and `y`, but at the same time allows us to have an array of points that is concrete and homogeneous (every point in the array is forced to be the same type)?  At first glance, this seems like a contradiction in terms.\n",
    "\n",
    "The answer is not to define a *single* type, but rather to **define a whole family of types** that are *parameterized* by the type `T` of `x` and `y`.  In computer science, this is known as [parametric polymorphism](https://en.wikipedia.org/wiki/Parametric_polymorphism).  (An example of this can be found in [C++ templates](https://en.wikipedia.org/wiki/Template_%28C%2B%2B%29).)\n",
    "\n",
    "In Julia, we will define such a family of types as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point3{Int64}(3,4)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immutable Point3{T<:Real}\n",
    "    x::T\n",
    "    y::T\n",
    "end\n",
    "Base.:+(p::Point3, q::Point3) = Point3(p.x + q.x, p.y + q.y)\n",
    "Base.zero{T}(::Type{Point3{T}}) = Point3(zero(T),zero(T))\n",
    "\n",
    "Point3(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `Point3` is actually a family of subtypes `Point{T}` for different types `T`.   The notation `<:` in Julia means \"is a subtype of\", and hence `T<:Real` means that we are constraining `T` to be a `Real` type (a built-in *abstract type* in Julia that includes e.g. integers or floating point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point3{Float64}(8.6,11.8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Point3(3,4) + Point3(5.6, 7.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, let's make an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000-element Array{Point3{Float64},1}:\n",
       " Point3{Float64}(0.0854553,0.0854553)\n",
       " Point3{Float64}(0.885596,0.885596)  \n",
       " Point3{Float64}(0.204148,0.204148)  \n",
       " Point3{Float64}(0.291398,0.291398)  \n",
       " Point3{Float64}(0.491761,0.491761)  \n",
       " Point3{Float64}(0.385552,0.385552)  \n",
       " Point3{Float64}(0.858012,0.858012)  \n",
       " Point3{Float64}(0.610907,0.610907)  \n",
       " Point3{Float64}(0.202762,0.202762)  \n",
       " Point3{Float64}(0.772584,0.772584)  \n",
       " Point3{Float64}(0.0807838,0.0807838)\n",
       " Point3{Float64}(0.942604,0.942604)  \n",
       " Point3{Float64}(0.525602,0.525602)  \n",
       " ⋮                                   \n",
       " Point3{Float64}(0.450704,0.450704)  \n",
       " Point3{Float64}(0.6765,0.6765)      \n",
       " Point3{Float64}(0.0218983,0.0218983)\n",
       " Point3{Float64}(0.60217,0.60217)    \n",
       " Point3{Float64}(0.601585,0.601585)  \n",
       " Point3{Float64}(0.906846,0.906846)  \n",
       " Point3{Float64}(0.0805392,0.0805392)\n",
       " Point3{Float64}(0.346368,0.346368)  \n",
       " Point3{Float64}(0.764284,0.764284)  \n",
       " Point3{Float64}(0.420253,0.420253)  \n",
       " Point3{Float64}(0.596481,0.596481)  \n",
       " Point3{Float64}(0.485411,0.485411)  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3 = Point3.(a,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the type of this array is `Array{Point3{Float64},1}` (we could equivalently write this as `Vector{Point3{Float64}}`, since `Vector{T}` is a synonym for `Array{T,1}`).  You should learn a few things from this:\n",
    "\n",
    "* An `Array{T,N}` in Julia is itself a parameterized type, parameterized by the element type `T` and the dimensionality `N`.\n",
    "\n",
    "* Since the element type `T` is encoded in the `Array{T,N}` type, the element type does not need to be stored in each element.  That means that the `Array` is free to store an array of \"inlined\" elements, rather than an array of pointers to boxes.  (This is why `Array{Float64,1}` earlier could be stored in memory like a C `double*`.\n",
    "\n",
    "* It is still important that the element type be `immutable`, since an array of mutable elements would still need to be an array of pointers (so that it could \"notice\" if another reference to an element mutates it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  samples:          407\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%\n",
       "  memory estimate:  0.00 bytes\n",
       "  allocs estimate:  0\n",
       "  minimum time:     10.10 ms (0.00% GC)\n",
       "  median time:      11.71 ms (0.00% GC)\n",
       "  mean time:        12.28 ms (0.00% GC)\n",
       "  maximum time:     23.28 ms (0.00% GC)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark sum($a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! It is again **only 10ms**, the same time as our completely concrete and inflexible `Point2`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
